import numpy as np
import random
from langchain_community.embeddings import GPT4AllEmbeddings
from .umap import umap

def gmm(documents, n_clusters):
    # Dimensionality of points
    dim = documents.shape[1]
    size = documents.shape[0]

    # All pi's should add up to 1
    random_numbers = np.random.rand(n_clusters)
    pi = np.array(random_numbers / np.sum(random_numbers))

    # Initialize means by randomly choosing data points
    mean = np.array(random.sample(documents.tolist(), k=n_clusters))  

    # Initialize responsibilities, which are the probabilities that a data point belongs to a specific cluster
    responsibilities = np.zeros([n_clusters, size])

    # Initialize covariance matrices by assigning each one as an identity matrix of size (classes, dim, dim)
    cov  = np.tile(np.identity(dim), (n_clusters, 1, 1))
    cov += np.eye(dim) * 1e-6

    # Compute responsibilities
    def expectation(pi, mean, cov):
        def get_gaussian_sum(gaussian):
            gaussian_sums = np.zeros([size]) # Sum of gaussian for (all)point j across all i classes
            for i in range(size):
                for j in range(n_clusters):
                    gaussian_sums[i] += gaussian[j, i]

            return gaussian_sums
        
        dif = np.zeros([n_clusters, size, dim])
        mahalanobis = np.zeros([n_clusters, size])
        exp = np.zeros_like(mahalanobis)
        N = np.zeros_like(exp)
        gaussian = np.zeros_like(N)

        for i in range(n_clusters):
            determinant = np.linalg.det(cov[i])
            normalization_constant = 1 / (((2 * np.pi) ** (dim/2)) * np.sqrt(determinant))

            for j in range(size): # each data point
                dif[i, j] = np.array(documents[j] - mean[i])
                mahalanobis[i, j] = np.dot(np.dot(dif[i, j].T, np.linalg.inv(cov[i])), dif[i, j])

                exp[i, j] = np.exp(-0.5 * mahalanobis[i, j])

                N[i, j] = normalization_constant * exp[i, j]
                gaussian[i, j] = pi[i] * N[i, j]

        gaussian_sums = get_gaussian_sum(gaussian)

        for i in range(n_clusters):
            for j in range(size):
                responsibilities[i, j] = gaussian[i, j] / gaussian_sums[j]
        return responsibilities, N, dif

    # Compute pi, mean, and cov using responsibilities obtained
    def maximization(responsibilities, dif):
        new_pi = np.zeros_like(pi, dtype=float)
        new_mean = np.zeros_like(mean, dtype=float)
        new_cov = np.zeros_like(cov, dtype=float)

        for i in range(n_clusters):
            resp_sum = np.sum(responsibilities[i])
            new_pi[i] = resp_sum / size
            new_mean[i] = np.sum([responsibilities[i, j] * documents[j] for j in range(size)], axis=0) / resp_sum
            new_cov[i] = np.sum([responsibilities[i, j] * np.outer(dif[i, j], dif[i, j].T) for j in range(size)], axis=0) / resp_sum
            new_cov[i] += np.eye(dim) * 1e-6  # Regularize covariance

        return new_pi, new_mean, new_cov

    def get_log_likelihood(N, pi):
        log_likelihood = 0
        for i in range(size):
            likelihood = 0
            for j in range(n_clusters):
                likelihood += pi[j] * N[j, i]
            log_likelihood += np.log(likelihood)

        return log_likelihood

    def EMAlgorithm(pi, mean, cov, max_itt=1000, min_gain=1e-6):
        old_log_likelihood = None
        for _ in range(max_itt):
            # E-step
            responsibilities, N, dif = expectation(pi, mean, cov)

            # Compute log-likelihood after E-step
            log_likelihood = get_log_likelihood(N, pi)

            # Check for convergence
            if old_log_likelihood is not None:
                gain = log_likelihood - old_log_likelihood
                if gain < min_gain:
                    break

            # M-step
            pi, mean, cov = maximization(responsibilities, dif)
            old_log_likelihood = log_likelihood

        return responsibilities, log_likelihood, pi, mean, cov

    responsibilities, log_likelihood, pi, mean, cov = EMAlgorithm(pi, mean, cov)

    return responsibilities, log_likelihood, pi, mean, cov

x = ['processing (EMNLP) , pp. 1532 -1543. 2014.  \n[13] Nakov, Preslav, Alan Ritter, Sara Rosenthal, Fabrizio Sebastiani, and \nVeselin Stoyanov. "SemEval -2016 task 4: Sentiment analysis in \nTwitter." In  Proceedin gs of the 10th international workshop on \nsemantic evaluation (semeval -2016) , pp. 1 -18. 2016.  \n[14] Arora, Sanjeev, Yingyu Liang, and Tengyu Ma. "A simple but tough -\nto-beat baseline for sentence embeddings." (2016).  \n[15] Agarwal, Apoorv, Boyi Xie, Ilia Vovsha, Owen Ra mbow, and \nRebecca Passonneau. "Sentiment analysis of twitter data." \nIn Proceedings of the Workshop on Language in Social Media (LSM \n2011) , pp. 30 -38. 2011.  \n[16] Pak, Alexander, and Patrick Paroubek. "Twitter as a corpus for \nsentiment analysis and opinion mining ." In LREc , vol. 10, no. 2010, \npp. 1320 -1326. 2010.', '·Features ·Social media ·Machine learning\n·Supervised algorithm ·Naive Bayes classiﬁer\n1 Introduction\nOpinion plays an important role in deciding about everything in the life asmillions of people express their thoughts through personal blogs, social network-ing sites and many more. Opinions are private states, which are not directlyobservable by others but expressions of opinion can be reﬂected through actionsincluding written and spoken languages [1]. Sentiment analysis which is alsoknown as opinion mining is a task in Natural Language processing which dealswith the discernment and categorization of opinions in narrative [ 2]. Predom- inantly, these opinions are classiﬁed into positive, negative and neutral classesand is thus helpful in many ﬁelds including marketing, sociology, psychology etc.[3] Sentiment Analysis is popular for English languages and it is found rarely forIndian Languages [4].Twitter, a microblogging stage, permits its clients to post short messagesabout any subject what’s more, tail others to get their posts. Many individuals\nc/circlecopyrtSpringer International Publishing Switzerland 2015R. Prasath et al. (Eds.): MIKE 2015, LNAI 9468, pp. 703–710, 2015.DOI: 10.1007/978-3-319-26832-3', '[1] Mohammad, Saif M., and Felipe Bravo -Marquez. "Emotion \nintensities in tweets."  arXiv preprint arXiv:1708.03696  (2017).  \n[2] Kiritchenko, S., Zhu, X. and Mohammad, S.M., 2014. Sentiment \nanalysis of short informal texts.  Journal of Artificial In telligence \nResearch , 50, pp.723 -762. \n[3] Mohammad, Saif M., Parinaz Sobhani, and Svetlana Kiritchenko. \n"Stance and sentiment in tweets."  ACM Transactions on Internet \nTechnology (TOIT)  17, no. 3 (2017): 26.  \n[4] Mohammad, Saif, Felipe Bravo -Marquez, Mohammad Salameh , and \nSvetlana Kiritchenko. "Semeval -2018 task 1: Affect in tweets." \nIn Proceedings of The 12th International Workshop on Semantic \nEvaluation , pp. 1 -17. 2018.  \n[5] Binali, Haji H., Chen Wu, and Vidyasagar Potdar. "A new significant \narea: Emotion detection in e -learning using opinion mining \ntechniques." In  2009 3rd IEEE International Conference on Digital', 'sentimental analysis task by collecting only the \npositive and negative reviews for the sentimental \nanalysis task.  \n This paper deals with the data that has been taken from the \nTwitter , the tweets from the Twitter  and we have named the \ncollected data as “Amrita -CEN -SentiDB1 ”. In this dataset \nonly the positive and t he negative tweets are taken into \nconsideration. The task here is to train the model with the \ndataset that is present and the trained model should classify \nthe correct class to which the sentence belongs to when \ntested with the test data.  The rest of the s ections are \narranged as follows Related works in Section [II], \nBackground in Section [III], Dataset description in Section \n[IV], Methodology in Section [V], Statistical methods in \nSection [VI], Experimental analysis and results in Section \n[VII], Conclusion  in Section [VIII].  \nII. RELATED WORKS  \nThis section all about deals with the existing methods from \nthe classical  to the current methods that are being followed \nin the sentiment analysis which uses the data from the \nTwitter, with the term frequency inverse docum ent \nfrequency ( tfidf) and the global vectors (g lovec ) as the', 'use Twitter as a platform to communicate with each other. The objective of thisexamination is to study client opinion communicated on Twitter and to add to asystem that permits observing it in the constant. Tweet planning among othersinclude spelling correction, equivalent word substitution, hyperlink cancellationand stop words are performed [5]. Notion is physically ordered the slant intothree classes: positive, neutral and negative, so as to make the preparation set forthe classiﬁer [6]. The classiﬁed tweets are utilized to make positive, neutral andnegative feeling lists. The sensational increment in the utilization of the internetas a method for correspondence has been joined by a sensational change in theway individuals express their opinion and perspective [7]. They can express theirsurveys online about items and administrations and also the perspectives aboutanything by means of social network (i.e. web journals, examination discussions).Sentiwordnet is one of the widely used lexicon resources for sentiment analysis,emotional analysis, opinion mining [8]. Sentiwordnet is an automatically createdlexicon with positive and negative scores [9,10].The contemporary work is done as slice of shared task in Sentiment Analysisin Indian Language (SAIL) 2015, constrain category. The task which containsthree classes (positive, negative, neutral) of twitter data in three languages -Hindi, Bengali and Tamil is to identify the sentiment of the given tweet in agiven', 'the authors have performed classi- ﬁcation about 6799 tokens of Twitter data to identify sentiment score. Rafeek Remyain [14] discussed methods to detect polarity in sentiment analysis regression models.He considered product review dataset and the evaluation results obtained showed animproved classiﬁcation accuracy.', '2015, constrain category. The task which containsthree classes (positive, negative, neutral) of twitter data in three languages -Hindi, Bengali and Tamil is to identify the sentiment of the given tweet in agiven language. The main objective of the share task is to stimulate researchersto accomplish sentiment analysis in their endemic language. Section 2provides a view about the methodology used in the system; Sect. 3discusses about the short analysis of the dataset provided to the work; Sect.4discusses about variousexperiments and their results.', 'sentiment analysis and opinion mining ." In LREc , vol. 10, no. 2010, \npp. 1320 -1326. 2010.  \n[17] Kouloumpis, E., Wilson, T. and Moore, J., 2011, July. Twitter \nsentiment analysis: The good the bad and the omg!. In  Fifth \nInternational AAAI conference on weblogs and social media . \n[18] Barbosa, Luciano, and J unlan Feng. "Robust sentiment detection on \ntwitter from biased and noisy data." In  Proceedings of the 23rd \ninternational conference on computational linguistics: posters , pp. 36 -\n44. Association for Computational Linguistics, 2010.  \n[19] Greenspan, Hayit, Bram Van Ginneken, and Ronald M. Summers. \n"Guest editorial  deep learning in medical imaging: Overview and \nfuture promise of an exciting new technique."  IEEE Transactions on \nMedical Imaging  35, no. 5 (2016): 1153 -1159.  \n[20] Poria, Soujanya, Erik Cambria, Devamanyu Hazarika, Navonil \nMajumder, Amir Zadeh, and Louis -Philippe Morency. "Context -\ndependent s entiment analysis in user -generated videos."', '1. Fink, C.R., et al.: Coarse- and ﬁne-grained sentiment analysis of social media text.Johns Hopkins APL Tech. Dig. 30(1), 22–30 (2011)2. Balahur, A.: Sentiment analysis in social media texts. In: 4th Workshop on Com-putational Approaches (2013) 710 S. Se et al.3. Hutto, C.J., Gilbertl, E.: Vader: a parsimonious rule-based model for sentimentanalysis of social media text. In: Eighth International AAAI Conference on Weblogsand Social Media (2014)4. Arunselvan, S.J., Anand kumar, M., et al.: Sentiment analysis of tamil mooviereviews via feature frequency count. IJAER 10, 17934–17939 (2015)5. Jansen, B.J., et al.: Twitter power: tweets as electronic word of mouth. J. Am.Soc. Inf. Sci. Technol.60(11), 2169–2188 (2009)6. Hiroshi, K., et al.: Deeper sentiment analysis using machine translation technology.In: 20th International Conference on Computational Linguistics (2004)7. John, G.H., Langley, P.: Estimating continuous distributions in Bayesian classiﬁers.In: Eleventh Conference on', 'hand, Sentimentanalysis allows the user express more precise feelings about a product or service inthe market. This is because, unlike the star system, sentiment analysis feeds off thereviews written by users. A user is free to use the complete English vocabulary toexpress his/her feelings axed weight to every possible emoticon, indicating whetherthe opinion is positive, negative, or neutral.', 'being studied and analyzed with the help of the \nmicroblogging  [16] [9]. The dataset which is used in the \ntask is of the Twitter  dataset and the corpus collection \nconsists of the various emoticons that corresponds to that of \nthe either happy or  sad. The SVM and the navie b ayes are \nused for the classification. The use r generated r eviews are \nan another task [10] [22] which has the lots of the sentiment \ndetails hidden in them so there are two methods of the study \nthat is being done Aspect Senti ment Unification Model and \nthe s entence  latent dirichlet allocation  (LDA ) [10] of w hich \nthe greater range of the learning is done with the help of the \nproposed terminology. So far the classical  methods are \nbeing discussed and now the automatic detection of the \nsentiment is proposed in this method [18]  [24] by removing \nthe noisy information fr om the data. The  primary task is to \nautomatically classify the positive or the negative sentiment \nin the given sentences [14] so the features used here are the \nmeta -features [18] with the two types of the classifiers such \nas the Subjective classifiers and the Pola rity classifiers.', 'anandkumar@cb.amrita.eduAbstract.The contemporary work is done as slice of the shared task inSentiment Analysis in Indian Languages (SAIL 2015), constrained vari-ety. Social media allows people to create and share or exchange opinionsbased on many perspectives such as product reviews, movie reviews andalso share their thoughts through personal blogs and many more plat-forms. The data available in the internet is huge and is also increasingexponentially. Due to social media, the momentousness of categorizingthese data has also increased and it is very diﬃcult to categorize suchhuge data manually. Hence, an improvised machine learning algorithm isnecessary for wrenching out the information. This paper deals with ﬁnd-ing the sentiment of the tweets for Indian languages. These sentimentsare classiﬁed using various features which are extracted using words andbinary features, etc. In this paper, a supervised algorithm is used for clas-sifying the tweets into positive, negative and neutral labels using NaiveBayes classiﬁer.Keywords:Sentiment analysis\n·Features ·Social media ·Machine learning\n·Supervised algorithm ·Naive Bayes classiﬁer\n1 Introduction', 'Sentiment Analysis is a rapidly growing ﬁeld of data analytics [ 1]. Sentiment is a thought, a judgment or an emotional response driven by a feeling. Sentiment Analy-sis, also known as opinion mining, deals with appraisal of peoples inclination towardsan entity. An entity can be anything with a commercial value. Sentiment analysishas its foundation on the world wide web. From a users perspective, various con-tents related to their personal and public life can be hosted through social mediaplatforms such as online social networking websites or e-commerce websites. Froma technical perspective, most social media websites are empowered with built-inApplication Programming Interfaces (APIs), prompting data collection and investi-gation by researchers and developers. Fundamentally, sentiment analysis affords aresourceful mechanism with the support of online data [ 2]. We propose Automated Review Analyzing System (ARAS), a new approach forassessment of customers market sentiments toward a product or service, though theirtransactions on of e-commerce websites. The prevailing system is the Star system,which analyzes a customers sentiment of a product expressed by a star value between1 and 5 (Fig.1). The basic ﬂaw of this strategy is the lack of choice. Users are onlygiven ﬁve options to rate the product. This can affect the realistic evaluation ofcustomers experience that the users provide. There are categories of users who feelthe', 'corpus learned seeds and polarity lexiconfor sentiment analysis. International Conference on Computing and Network Communications,CoCoNet (2015)12. Hu, M., Liu, B.: Mining and summarizing customer reviews In: Proceedings of the tenth ACMSIGKDD international conference on Knowledge discovery and data mining. pp. 168–177.ACM, New Y ork, NY , USA (2004)13. Gann, W.-J.K., Day, J., Zhou, S.: Twitter analytics for insider trading fraud detection systemIn:. Proceedings of the Sencond ASE International Conference on Big Data. ASE (2014)14. Rafeek, R., Remya, R.: Detecting contextual word polarity using aspect based sentiment analy-sis and logistic regression. IEEE International Conference on Smart Technologies and Manage-ment for Computing, Communication, Controls, Energy and Materials, ICSTM 2017—Pro-ceedings (2017)15. Pang, B., Lee, L.: Opinion mining and sentiment analysis. Found Trends Inf Retr 2(1–2):1135(2008)', 'technology.In: 20th International Conference on Computational Linguistics (2004)7. John, G.H., Langley, P.: Estimating continuous distributions in Bayesian classiﬁers.In: Eleventh Conference on Uncertainty in Artiﬁcial Intelligence (1995)8. Godbole, N., et al.: Large-scale sentiment analysis for news and blogs. ICWSM 7, 21 (2007)9. Kouloumpis, E.: Twitter sentiment analysis: the good the bad and the omg!. Icwsm11, 538–541 (2011)10. Pang, B., Lee, L.: Opinion mining and sentiment analysis. Found. Trends Inf. Retr.2(1–2), 1–135 (2008)11. Mikolov, T., et al.: Eﬃcient estimation of word representations in vector space(2013). arXiv preprintarXiv:1301.378112. Turney, P.D., et al.: From frequency to meaning: vector space models of semantics.J. Artif. Intell. Res.37(1), 141–188 (2010)13. Rennie, J.D., et al.: Tackling the poor assumptions of naive bayes text classiﬁers.In: ICML, vol. 3 (2003)14. Jordan, A.: On', '1≤k≤n d≤np(t k|c) (1)As shown in the Fig.2, the tweets are taken and if it includes any punctua-tions other than exclamations and question marks, it is removed and the tweetids are also processed. If the tweet has any binary feature, they are marked 1. AMRITA-CEN@SAIL2015: Sentiment Analysis in Indian Languages 707\nFig. 2.Tweets-before and after preprocessing\n3 An Analysis of SAIL Dataset', 'in the sentiment analysis which uses the data from the \nTwitter, with the term frequency inverse docum ent \nfrequency ( tfidf) and the global vectors (g lovec ) as the \nfeature extraction. Sentiment is considered as the emotion \nwhich means the emotion pertains to the particular feeling \nrather the sentiment pertains to the general perspective of \nthe task [15]  [25]. The author of this paper aims for the \ndetection of the intensity of the emotion from the text. Here \nthe four types of the emotions are considered they are anger, \nfear, joy and sadness [17]. The datasets are annotated by \nusing the method called as the Best Wo rst Scaling  (BWS)  \n[2]. The dataset that has been created is the first ever type of \nthe dataset that has been created for the emotion intensity \nthat has been annotated with the BWS method, the \nbenchmark system has been created with the regression \nsystem by conducting the various experiments on them [1] \n[2]. The Twitter  data and the Short Message Service ( SMS ) \nare being used  as a part of the semeval 2013 task were in \nthe SVM gives an accuracy of about 71.9% which they have \nclaimed as the best by using the su pervised statistical', 'ﬂaw of this strategy is the lack of choice. Users are onlygiven ﬁve options to rate the product. This can affect the realistic evaluation ofcustomers experience that the users provide. There are categories of users who feelthe ﬁve-star rating is insufﬁcient to express their views. People who wish to rate aproduct less than 1 star or those who wish to rate a product between 1 star and 2stars, etc., belong to this category. Some people feel that a particular product doesnot deserve even a single star or at other instances, a user feels that the product(or service) deserves more than 5 stars. For example, a user who had a horribleexperience with the product is constrained to rate it 1 star whereas a user who hadthe best experience is unable to rate it over 5 stars. On the other hand, Sentimentanalysis gives the user express more precise feelings about a product or service inthe market. This is because, unlike the star system, sentiment analysis feeds off thereviews written by users. A user is free to use the complete English vocabulary toexpress his/her feelings.', '[9] Cambria, Erik, Björn Schuller, Yunqing Xia, and Catherine Havasi. \n"New avenues in opinion mining and sentiment analysis."  IEEE \nIntelligent systems  28, no. 2 (2013): 15 -21. \n[10] Jo, Yohan, and Alice H. Oh. "Aspect and sent iment unification model \nfor online review analysis." In  Proceedings of the fourth ACM \ninternational conference on Web search and data mining , pp. 815 -824. \nACM, 2011.  \n[11] Khan, Aurangzeb, Baharum Baharudin, Lam Hong Lee, and \nKhairullah Khan. "A review of machin e learning algorithms for text -\ndocuments classification."  Journal of advances in information \ntechnology  1, no. 1 (2010): 4 -20. \n[12] Pennington, Jeffrey, Richard Socher, and Christopher Manning. \n"Glove: Global vectors for word representation." In  Proceedings of \nthe 2014 conference on empirical methods in natural language \nprocessing (EMNLP) , pp. 1532 -1543. 2014.  \n[13] Nakov, Preslav, Alan Ritter, Sara Rosenthal, Fabrizio Sebastiani, and', 'work should exploredifferent recurrent neural networks (RNN) including bi-directional recurrent NN andLong-ShortTerm Memory (LSTM) RNNs that try to capture aspect-speciﬁc senti-ment through context. In [9], authors have performed classiﬁcation of text usingvarious algorithms. Pang and Lee [10] suggested removal of objective sentencesby extracting the subjective ones among them. They proposed a text-categorizationtechnique that can be used in the identiﬁcation of subjective content. A novel semi-supervised approach was proposed by Sanagar Gupta to construct polarity lexiconusing iterative Latent Semantic Analysis technique [ 11] from unlabeled multiple source domains corpus. This technique was proven to have a considerable gain inthe accuracy compared to the models until then. Hu and Liu [ 12] summarized a list of positive and negative words based on customer reviews. While the positive listcontained 2006 words, the negative list had 47,883 words. The problem with thisclassiﬁcation scheme was that both the lists contained many misspelled words, acommon circumstance in the digital ﬁeld. In [ 13], the authors have performed classi- ﬁcation about 6799 tokens of Twitter data to identify sentiment score. Rafeek Remyain [14] discussed methods to detect polarity in sentiment analysis regression models.He considered product review dataset and', 'area: Emotion detection in e -learning using opinion mining \ntechniques." In  2009 3rd IEEE International Conference on Digital \nEcosystems and Technologies , pp. 259 -264. IEEE, 2009.  \n[6] Desmet, Bart, and VéRonique Hoste. "Emotion detection in suicide \nnotes."  Expert Systems with Applications  40, no. 16 (2013): 6351 -\n6358.  \n[7] Bhaskar, Jasmine, K. Sruthi, and Prema Nedungadi. "Enhanced \nsentiment analysis of informal textual communication in social media by considering objective words and intensifiers." In  International \nConference on Recent Advances and Innovations in Engineering \n(ICRAIE -2014) , pp. 1 -6. IEEE, 2014.  \n[8] George, Anon, Barathi Ganesh HB, and K. P. Soman. "Teamcen at \nsemeval -2018 task 1: global vectors representation in emotion \ndetection." In  Proceedings of the 12th international workshop on \nsemantic evaluation , pp. 334 -338. 2018.  \n[9] Cambria, Erik, Björn Schuller, Yunqing Xia, and Catherine Havasi. \n"New avenues in opinion mining and sentiment analysis."  IEEE', 'topic or whatever the situation pertain to so that the mood of \nthe person can be judged. But the emotion is same for each \nand every person irrespective of the gender, but it changes \naccording to the mood and the mindset of the  person [5] \n[12]. But the difference in opinion is leading to a lot of the \nnegative impact so to prevent the suicidal incidents the \nmodel ha s been created for which the f1 -score of the model range is of 68.86% is achieved with the difference in the \nvariety  of the  emotions [6] [11]. The machine and the deep \nlearning approach are used to classify the type of the \nemotion in order to prevent the cases, through the text the \nstate of the pe rson is being well defined. Nowa days the \ntechnique called as the microblog ging is upcoming famous \nwhen compared to that of the classical  methods, one’s  \nopinion are being shared and read by the means of the \nblogging [16]. So the likes and the dislike s of the person are \nbeing studied and analyzed with the help of the \nmicroblogging  [16] [9]. The dataset which is used in the \ntask is of the Twitter  dataset and the corpus collection', '1. Kim, S.-M., Hovy, E.: Determining the sentiment of opinions In:. Proceedings of the 20thInternational Conference on Computational Linguistics, p. 1367. Association for Computa-tional Linguistics, Stroudsburg, PA, USA2. Xing, F., Zhan, J.: Sentiment analysis using product review data, Department of ComputerScience, North Carolina A T State University, Greensboro, USA (2015)3. Chesley, P ., Vincent, B., Xu, L., Srihari, R.K.: Using verbs and adjectives to automaticallyclassify blog sentiment. Training 580(263), 233 (2006) 4. Liu, B.: Sentiment analysis and opinion mining. Synthesis Lectures on Human LanguageTechnologies. Morgan Claypool Publishers 338 A. C. Jishag et al.5. Thara, S., Sidharth, S.: Aspect based sentiment classication: SVD features. International Con-ference on Advances in Computing, Communications and Informatics, ICACCI (2017)6. Hu, M., Liu, B.: Mining and summarizing customer reviews. KDD 04, 2004 (2004) 7. Paulus, R., Socher, R., Manning, C.D.: Global belief recursive neural networks. In: Advancesin Neural Information Processing Systems 2014, pp. 2888–28968.', 'tweets. The tweets are categorized as the positive and the \nnegative t weets based on the subject matter to which they \nbelong to, they are labelled as 0, stands for the negative \nIEEE - 45670\n10th ICCCNT 2019 \nJuly 6-8, 2019, IIT - Kanpur, \nKanpur, India \nAuthorized licensed use limited to: Amrita School Of Engineering - Kollam. Downloaded on August 27,2024 at 04:42:00 UTC from IEEE Xplore.  Restrictions apply.  reviews and the 1 , stands for the positive review. The main \nsource of the data is the internet which means that the data is \ncollected by the online pub lically available dataset for the \niphone reviews, movie reviews, weather reviews, general \nreviews that are clubbed together so that the dataset contains \nthe multiple view points from the various sources. By this \nmethod the new dataset is created consisting  of only positive \nand the negative reviews which is a total sentence of about \n4,00,000. Out of which , 2,00,000 is of the positive sentences \nand negative sentences each. The dataset is made to run in \nthe deep learning algorithm with the various split s and th e \nresults are tabulated in the Table I below:', 'The user has r equest ed enhanc ement of the do wnlo aded file. Automated Review Analyzing SystemUsing Sentiment Analysis\nA. C. Jishag, Vishnu Rakhesh, Suraj Mohan, N. Vinayak V arma,V aisakh Shabu, Lekshmi S. Nair and Maya MenonAbstractAn integral part of human behavior has always been to ﬁnd out what othersthink about what would happen next. With the ongoing trend of e-commerce websitesand personal blogs, people make active use of various technologies to understand andclassify opinions. This paper introduces a new system to understand the emotions andfeelings underlying the reviews provided by users on various e-commerce websites.This system holds an edge over the current rating system of star values by providingthe users with a more precise and descriptive result. The main disadvantage of thestar system is that it does not provide enough choice to the user. The methodologymentioned in this paper, named ARAS or Automated Review Analyzing System,overcomes this issue by using sentiment analysis which feeds upon each word in thereview rather than a separate weighing system.KeywordsSentiment analysis\n·Review system ·Lexicon method ·Web crawling', 'We propose an Automated Review Analyzing System (ARAS), a new approachfor assessment of customers market sentiments toward a product or service, thoughtheir transactions on of e-commerce websites. The prevailing system is the Starsystem, which analyzes a customers sentiment of a product expressed by a star valuebetween 1 and 5 (Fig.1). The basic ﬂaw of this strategy is the lack of choice. Usersare only given ﬁve options to rate the product. This can affect the realistic evaluationof customers experience that the users provide. There are categories of users whofeel the ﬁve-star rating is insufﬁcient to express their views. People who wish torate a product less than 1 star or those who wish to rate a product between 1 starand 2 stars, etc., belong to this category. Some people feel that a particular productdoes not deserve even a single star or at other instances, a user feels that the product(or service) deserves more than 5 stars. For example, a user who had a horribleexperience with the product is constrained to rate it 1 star whereas a user who hadthe best experience is unable to rate it over 5 stars. On the other hand, Sentimentanalysis allows the user express more precise feelings about a product or service inthe market. This is because, unlike the star system, sentiment analysis feeds off thereviews written by users. A user is free to use the complete English vocabulary', 'which abundance amount of the text data are generated [5] \n[16]. \n \n Text is a way through which the emotions are being \nexpressed irrespective of the language because the language \ndiffers from place t o place were as the emotion contained in \nthe text remains the same [3] [9]. All the actions of the \nliving beings expresses their emotion towards them . The \npresent era in which we are living is 21st century were the information has a great value, that is we  live in information \nage Internet have become easily accessible to everyone [7] \n[10]. The digital identity of the person are created when \npeople began to use the social media resources like \nFacebook, Twitter , Instagram, G -mail, Snapcha t, Whatsup, \nYoutube a nd in the e -commerce  websites such as the \nAmazon, F lipkart, Snapdeal  etc. the most commonly used \nwebsites. The text data that is created in the social media are \nbound to the certain information it contains say some social \nissue, political issue, product re view, movie review \ncommented by people  publically [8], early days ones \nopinions cannot be shared in the large manner by the power \nof the social media and the generous opinions of the user so', '3 Methodology\nNumerous websites/companies resort to Sentiment Analysis as a process to appraisethe current trends in customer satisfaction or product acceptance. On the other hand,users provided with the star rating system, discussed earlier, are restricted to providean unfeigned assessment of the quality of any product or service. Companies rely onsentiment analysis rather than the star system, as the former offers their Customersunhindered options to express their experience of a product or service. Automated Review Analyzing System … 333\n3.1 W eb Scraping', 'Abstract — Powerful weapon in today’s world  is ones emotion \nis social media. They have the power to make an individual \ntrendin g overnight or even may pull down  anyone reputation. \nIn this paper , the sentiment analysis task has been performed \nby collecting the dataset from the publically available sources \nand by merging  them together  to for m a new dataset for the \nsentiment analysis  task that is positive or negative sentiment \nbased  on the context of the subject. A new reliable  dataset is \nsubjected to various pre -processing techniques and then the \nfeature extraction techniques aftermath  they are passed to the \ndeep learning technique s out of which by using the text \nrepresentation method , global vectors ( glovec ) with the  long \nshort -term memory ( lstm) has the highest accu racy of 75%, \nwhich is the bench mark accuracy for this dataset. For the \nresearch purpose the dataset used in this paper is made \navailable publically for research purpose.  \n \nKeywords — Twitter , Sentiment, Sentiment analysis, Text \nrepresentation, Machine learning, Deep learning.  \nI. INTRODUCTION  \nThe usage of t he mobile phones are common nowa days, \nwhich has led to a very large scal e users of the social media', 'Hindi 55.67 % 45.79 % 57.37 % 80.0 %\nBengali 33.6 % 29.58 % 34.44 % 39.26 %\nFig. 3.Bar chart representation of the ﬁnal result\n5 Conclusion and Future Work\nWe have presented a method to classify twitter data based on the sentimentwhich is highly useful in the ﬁeld of information retrieval (IR). In this work,we classify the tweets of the Indian languages into positive, negative and neu-tral classes. Generally before classifying the tweets, preprocessing is done. Thisis carried out in order to eliminate the unwanted symbols and also to retrievewords which are highly useful for analysing sentiment. The preprocessing stepis taken extra care of and it gave better result after classiﬁcation. Naive Bayesalgorithm is used which gives a better classiﬁcation result. This method can alsobe extended using SVM classiﬁer and also the unsuupervised way of implemen-tation can be done as future work.\nReferences', 'AMRITA-CEN@SAIL2015: Sentiment Analysisin Indian Languages\nShriya Se(B), R. Vinayakumar, M. Anand Kumar, and K.P. Soman\nCentre for Excellence in Computational Engineering and Networking,Amrita Vishwa Vidyapeetham, Ettimadai, Coimbatore, India{shriyaseshadrik.r,vinayakumarr77 }@gmail.com,m', 'prediction as it can capture the latent relation among the data. In [ 5], authors have suggested classiﬁcation using SVM.Hu and Liu [6] proposed several methods to analyze customer reviews from acorpus containing all types of reviews, such as negative, positive, and neutral. Theyidentiﬁed the customer opinions and emotions and classiﬁed them as positive or 332 A. C. Jishag et al.', '04, 2004 (2004) 7. Paulus, R., Socher, R., Manning, C.D.: Global belief recursive neural networks. In: Advancesin Neural Information Processing Systems 2014, pp. 2888–28968. Lakkaraju, H., Socher, R., Manning, C.: Aspect speciﬁc sentiment analysis using hierarchicaldeep learning. In: Advancesmensts and Applications of Deep Learning in computer Systems(2014)9. Vijayan, V .K., Bindu, K.R., Parameswaran, L.A.: Comprehensive study of text classiﬁcationalgorithms. International Conference on Advances in Computing, Communications and Infor-matics, ICACCI (2017)10. Pang, B., Lee, L.L.: A sentimental education: Sentiment analysis using subjectivity sum-marization based on minimum cuts In: Proceedings of the 42nd Annual Meeting on Asso-ciation for Computational Linguistics, ACL 04. Association for Computational Linguistics,Stroudsburg, PA, USA (2004)11. Sanagar, S., Gupta, D.: Adaptation of multi-domain corpus learned seeds and polarity lexiconfor sentiment analysis. International Conference on Computing and Network Communications,CoCoNet (2015)12. Hu, M., Liu, B.: Mining and summarizing customer reviews In: Proceedings of the tenth', 'Fig. 2Graph containing sentiment value for the ﬁrst 100 reviews Automated Review Analyzing System … 335\nFig. 3Sentiment value generated for each hotel\nFig. 4Sentiment Analysis result generated for each hotel 336 A. C. Jishag et al.', 'and negative sentences each. The dataset is made to run in \nthe deep learning algorithm with the various split s and th e \nresults are tabulated in the Table I below:  \nTABLE I.  DATASET DESCRIPTION  \nDataset  Split  Positive  Negative  Total  \nTraining  60:40  1,20,000  1,20,000  4,00,000  \nTesting  80,000  80,000  \nTraining  70:30  1,40,000  1,40,000  4,00,000  \nTesting  60,000  60,000  \nTraining  80:20  1,60,000  1,60,000  4,00,000  \nTesting  40,000  40,000  \nTraining  90:10  1,80,000  1,80,000  4,00,000  \nTesting  20,000  20,000  \nV. METHODOLOGY  \nThe sentiment are of the two major types such as the \npositive and the negative. The positive and the negative  \nsentiments  are based on the tone and the expression of the \nfeeling towards the particular context of the subject. Here \ncomes an example “I am happy” in this context the word', 'the data  are converted into the words as the part of the pre -\nprocessing technique. For example , the “23” will be \nconverted into the “twenty three”. In some cases , the letter \n“2” will be used in the words instead of the word “to” here \nin this sentence “I went 2 the market” here the “2” refers to \n“to”. So these are some of the challenging task when it \ncomes to the conversion of the numbers. Suppose if the \nnumber “2” is removed directly then the sentence becomes \nincomplete.  \n3) Removal of the punctuations and special ch aracters : \nThe data used in this work is the Twitter  data which mainly \nfocuses on the tweets, so while tweeting the original \nemotion of the person is expressed in the words. The tweets \nconsists of the lots of the special characters, punctuations, \naccent mar ks and emojis. The main challenging role in the \ntext data pre -processing comes here is that many languages \nare spoken world -wide so the pronunciation of the word \ndiffers in each place  so in order to spell the word correctly', 'the corpus to eliminatestop words. The process of Stemming is now applied to the corpus and the ﬁnal,preprocessed corpus is made into a term–document matrix. A document-term matrixrepresents frequency of words with respect to collection of documents in matrix form.Each term in the matrix is now compared with two dictionaries, positive lexicon setand negative lexicon set. Positive Lexicon set would contain words that provide apositive sentiment to the sentence negative lexicon set would contain words thatprovide a positive sentiment to the sentence. Each word is tagged with a weight withrespect to the intensity of the sentiment it provides to the context. 334 A. C. Jishag et al.', 'shown in the Table IV.  \nTABLE IV.  RESULTS FOR DEEP LEA RNING APPROACH  USING GLOVEC  \nMethod  Classifie rs Accuracy  \nGlovec  LSTM  75.3 \nGRU  63.2 \nSimple RNN  69.5 \nVIII. CONCLU SION \nThis paper evaluates the performance of linear and non -\nlinear text representation methods for sentimental analysis.  \nThe collected dataset  “Amrita -CEN -SentiDB1 ” is subjected \nto various non -linear text representation methods with the \ndeep learning architecture which performs better than the \nlinear text representation with the machine learning \nalgorithms. The performance of the proposed method can be \nincreased experimentally by hyper parameter  tuning the \nnetwork . This is the benchmark accuracy for this dataset \nfurther the dataset is made publically available for the \nresearch purpose.  https://vinayakumarr.github.io/Amrita -\nCEN -SentiDB1/  \nREFERENCES  \n[1] Mohammad, Saif M., and Felipe Bravo -Marquez. "Emotion \nintensities in tweets."  arXiv preprint arXiv:1708.03696  (2017).', '5 Conclusion and Further Improvements\nWe have done experimentation in a larger database considering reviews from 10different websites and attained an accuracy of 94%. The future scope for this modelon the followings.\n5.1 Semantics\nOur algorithm computes the overall sentiment of user reviews. Polarity plays a bigrole in sentiment analysis. For example, imagine the case of a review where the userpraises the hygiene of the hotel but is disappointed with its locality. This is a positivereview for a user, who gives priority to the hygiene but on the other hand a user whocares more about the locality would rate this as a negative review. This difﬁculty ofclassiﬁcation was overcome in the suggested model as the classiﬁcation dependedon the query term this emphases on the semantics. Automated Review Analyzing System … 337\n5.2 Part of Speech (POS) T agger\nThe POS tagger takes a notably long time for training the system. This, in turn, led toa big spike on the execution time of the model. It did improve the computed accuracy,but we did not have enough time to conduct these tests.\n5.3 Support V ector Machines\nPang and Lee [15] showed that SVM performed the best when classifying moviereviews as positive or negative. An important next step would be to further exploreSVM parameters for classifying reviews.', 'classified into two ma jor types  such as the supervised and \nunsupervised. They outperforms well for the classification \ntasks when it comes to the smaller data but once the large \ndataset is passed there comes a problem. That is rectified by \nthe means of the deep learning algo rithms  [23]. The feature \nextraction methods and the vectorization determines the \nperformance of the algorithm. The main objectives of this \nwork are as follows:  \n1. To develop a Twitter  database for the sentimental \nanalysis.  \n2. To perform various text representati on methods \nand to evaluate those methods on the sentimental \ndatabase.  \n3. To do a comparative study on the sentimental \ndatabase by using the deep learning techniques.  \nIEEE - 45670\n10th ICCCNT 2019 \nJuly 6-8, 2019, IIT - Kanpur, \nKanpur, India \nAuthorized licensed use limited to: Amrita School Of Engineering - Kollam. Downloaded on August 27,2024 at 04:42:00 UTC from IEEE Xplore.  Restrictions apply.  4. To develop an improved  database for the \nsentimental analysis task by collecting only the \npositive and negative reviews for the sentimental \nanalysis task.', 'commented by people  publically [8], early days ones \nopinions cannot be shared in the large manner by the power \nof the social media and the generous opinions of the user so \nmany things are changed and will be changing  [18].  \n \nThe text that  are pre sent in the social media are of three \nmain types such as the Mixed Script (which is a \ncombination of both the native script and the roman script), \nCode -Mixed Script (this  is a special type which is the \ncombination of the native and the English language that is \nwritten in the roman script), Native Script (it refer to the \nnative or regional lang uage of that particular region). So \nwhen compared to all the text that are available , the most \nused type of the script is the code mixed script [2] [15].  \n \nIn the current method the machine learning is paving the \npath in the various fields , one such is the natural language \nprocessing, here the data used for the processing is the text \ndata [22]. Primarily, m achine learning algorithms are \nclassified into two ma jor types  such as the supervised and \nunsupervised. They outperforms well for the classification \ntasks when it comes to the smaller data but once the large', 'I. INTRODUCTION  \nThe usage of t he mobile phones are common nowa days, \nwhich has led to a very large scal e users of the social media \nwhich on other hand has become tremendously powerful \n[1]. The information shared in the social media is so fast and \nquick that anything happens in any part of the world is \ncoming to light within minutes  [2]. In the classical  days, \npeople were busy in their work relying on the radio, \ntelevision, n ewspapers , etc. for the information [3] [ 6], it \ntakes time to reach the people. But things started changing \ndevices are becoming smarter than the humans, just one \nclick the information is in ou r hands. The information which \nare shared are in the form of the text so the text analytics, \nlinguistics are the blooming era now. But the machine s are \nsmarter than people [ 4] [ 8] they have the ability to \nunderstand the text through the algorithms that are  \nexclusively done for  them. Social media is the platform in \nwhich abundance amount of the text data are generated [5] \n[16]. \n \n Text is a way through which the emotions are being \nexpressed irrespective of the language because the language', 'Sentiment Analysis can be performed in two ways: Lexicon method and machinelearning. In the Lexicon approach, sentiment value is obtained by comparing thedataset being reviewed with two pre-deﬁned value sets, whereas in machine learningapproach, the dataset is divided into test set and training set. Training set is usedfor the learning process, followed by processing the test set for prediction of thesentiment value. The proposed model uses the lexicon method rather than Machinelearning to ﬁnd the sentiment value of the reviews. This is because even thoughreviews are plentiful in any e-commerce website, a corpus generated from thesereviews is not generally long enough to perform adequate supervised learning onInitially, the whole review set is made into a corpus. This corpus would contain stopwords, punctuation, and numbers, etc., which provide no impact on the sentimentvalue. Hence, these unwanted peripheral items are removed in the preprocessing step.Punctuation numbers are removed ﬁrst followed by the removal of white spaces. Allthe words in the corpus now are transformed into lower case. Next, a predeﬁneddictionary of stop words is now loaded and is compared with the corpus to eliminatestop words. The process of Stemming is now applied to the corpus and the ﬁnal,preprocessed corpus is made into a term–document matrix. A document-term matrixrepresents', 'from the training dataset which is already labelled. A smallpart of the data from the training dataset say about 10 % is taken and given forthe validation process. This is given as an input for the Naive Bayes classiﬁer and AMRITA-CEN@SAIL2015: Sentiment Analysis in Indian Languages 705', 'Fig. 2.Tweets-before and after preprocessing\n3 An Analysis of SAIL Dataset\nSAIL stands for Sentiment Analysis for Indian Languages. They have releasedtwitter dataset for three languages namely Tamil, Hindi, Bengali. The size of thetraining and testing dataset is shown in Table3in which approximately 27 % oftraining data of Tamil and Hindi and 54 % of the Bengali data contain URLs.Most of the Tamil tweets are regarding movie reviews and comments about someactors and actresses whereas the Hindi tweets are based on politics. The datasethas issues such as single tweet are there in both of the positive and negativetraining data and also there are tweets which are repeated. Many of these tweetsare misspelt which aﬀect the accuracy of the classiﬁer. The training dataset ofTamil tweets contains more colloquial words which is not present in Sentiwordnetand hence it is not clean whereas the Hindi and Bengali tweets are conventional.In the test data, many of the ambiguous tweets are present. As these data arealready ambigiuous, the accuracy drops.\nTable 3.Twitter training dataset for SAIL 2015 shared task\nLanguage Training data Test data\nPositive Negative Neutral Total\nTamil 387 316 400 1103 560\nHindi 168 545 493 1222 467\nBengali 277 354 368 999500 708 S. Se et al.', 'are being used  as a part of the semeval 2013 task were in \nthe SVM gives an accuracy of about 71.9% which they have \nclaimed as the best by using the su pervised statistical \nmethod for the text classification [3]  [23]. Emotions can be \nexpressed by the opinions or the facts the opinions are much \nmore valuable than that of the facts because the opinions \nhave the i ntensity of the emotions so nowa days the artificia l \nintelligence is playing a vital role which is changing all the \nindustry to move on to it were in the computers can \nunderstand the [8] [13] language with the help of the text \nrepresentation techniques that are being used for the feature \nextraction task so  the worst scaling method is used in the \nprocess of the annotation of the data [4] [7]. The model will \nbe judged based on the data if the dataset collected is good \nand obviously the trained model will be good. The text is so \npowerful  that the person intere st can easily be known to the \ntopic or whatever the situation pertain to so that the mood of \nthe person can be judged. But the emotion is same for each \nand every person irrespective of the gender, but it changes', 'in the given sentences [14] so the features used here are the \nmeta -features [18] with the two types of the classifiers such \nas the Subjective classifiers and the Pola rity classifiers. \nThese are some of the study done on the existing methods \nfor the sentiment analysis from the classical  method to the \nrecent methods.  \n \nThe motivation of the paper is to create a database from the \nvarious publically available datase ts for various reviews and \nto apply the classical machine learning methods over the \ntraditional methods in order to study the dataset collected. \nThe paper stands alone from the existing methods by the \nfollowing ways : the da ta used here is unique with the w ord \nembedding techniques for the machine learning and the deep \nlearning algorithm creating a benchmark accuracy of about \n75% for this dataset.  \nIII. BACKGROUND  \nA. Term Frequency I nverse Document Frequency ( tfidf) \nTerm Frequency Inverse Document Frequency  (tfidf) is  \ncommonly used for the purpose of the vectorising, aftermath \nthe features are extracted from them. The vectorising is done \nby the means of the assigning the weight to the extracted \nfeature for the process of extraction of the information. The', 'Marketing intelligence is the external data collected by a company about a speciﬁcmarket which it wishes to enter, to make decisions. It is the ﬁrst set of data whichthe company analyses before making any investment decision. An important hurdlefor Market Intelligence is the process of gathering consumer opinions of competingproducts and establishing thresholds as to benchmarks for products and services.Currently, no automated system is able to perform visual comparison of consumeropinions as proposed in this paper.One of the main problems in sentiment analysis is the categorization of polarity[3]. Given a text span, it requires some intelligence or learning to categorize thetext into a speciﬁc polarity. In [4], authors have deﬁned three category document-level, sentence level, and entity aspect level The document-level is concerned aboutthe overall sentiment of the document, While sentence-level and entity aspect-levelanalysis human opinion.Singular value decomposition (SVD) is a means of decomposing a matrix into aproduct of three simpler matrices. Algorithms on machine learning and sentimentanalysis normally use Singular V alue Decomposition (SVD) based feature for sen-timent prediction as it can capture the latent relation among the data. In [ 5], authors have suggested classiﬁcation using SVM.Hu and Liu [6] proposed several methods to analyze customer reviews from acorpus containing', 'negative, ignoring the neutral ones. However, this technique is primarily based onunsupervised itemset mining, which is amenable for analysis when the user writes acomplete, fully formatted review. This technique cannot be implemented for reviewswhich are very brief. Recent works [PSM14] [ 7] introduced a new model that allows neural nets (NN) to evaluate contextual sentiment: The proposed Global Belief-Recursive Neural Network (RecNN) represents the granular sentiment analysis. Abackward step from upper tree nodes is introduced their methodology in order tofaithfully capture contextual sentiment. A different approach is obtained by consid-ering aspect-speciﬁc sentiment analysis, using hierarchical deep learning accordingto [LSM] [8]. Here, separate aspect sentiment (SAS) models or Joint Multi-AspectSentiment (JMAS) models train root node-level softmax classiﬁers, a commonlyused classiﬁer after SVM with a different loss function, with aspect and sentimentas classiﬁcation outputs. However, a relabeling of product features is necessary forthese models, mentioned above by Hu, M. and Liu, B. Their work should exploredifferent recurrent neural networks (RNN) including bi-directional recurrent NN andLong-ShortTerm Memory (LSTM) RNNs that try to capture aspect-speciﬁc senti-ment through', 'sentiments  are based on the tone and the expression of the \nfeeling towards the particular context of the subject. Here \ncomes an example “I am happy” in this context the word \nhappy refers to the positive state were as “I cannot do this” \nin this context the word cannot mention to the negative \nstate. The Figure I  below explains the flow process that is \ncarried on along with this work.  \n \n \n \nFIGURE I.  FLOWCHART OF THE PROC ESS \n \nVI. STATISTICAL MEASURES  \nIn this work , to measure the performance of the deep \nlearning trained models, we estimate  the confusion matrix. \nThe confusion matrix is the one which decides the quality of \nthe model that is trained by the means of comparing with the \nactual class with that of the predicted class, here the actual \nclass refers to the data that is belonging to th at particular \ngroup, the predicted class refers to the trained model when \ntested the machine predicts one class depending upon the \ntraining. They are also called as the error matrix, they give the actual classification rate from the test data with the \nsymb olic representation as that of the true positive, true \nnegative, false positive, false negative. Now the terms are', 'This comparison results in obtaining the overall sentiment of each review, whichin turn gives the overall sentiment of the product mentioned in the reviews. Thisobtained value, which would give us the percentage acceptance or rejectance of theproduct in the market is then used to plot different graphs. Graphs provide greaterinsight into the growth and decay of the products market performance. Four graphsare generated for this purpose. Figure2is a graph that shows the sentiment value obtained for the ﬁrst 100 reviews. This graph will help the user understand the latestratings of the hotel/product, i.e., if the hotel was receiving better reviews lately orwere the sentiment value going down ever since. Every value in the star system hasan upper bound and a lower bound. For example, 1 star can be taken in place of anyvalue between 0 and 20%. This lower range and higher range is compared with theARAS-generated sentiment value in Fig. 3, where itsX-axis contains the name of each hotel while theY-axis shows the percentage sentiment value. Figure 4is an example of the results of a hotel, JW Marriot, shown as a bar graph portraying thepercentage of positive and negative reviews. It acts as a ﬁnal answer to the questionof how good the hotel is?This indicates the inefﬁciency of the star system in delivering a precise rating tothe user. Also, at odd times, the', 'See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/332102965\nAutomated Review Analyzing System Using Sentiment Analysis\nChapt er · Januar y 2019\nDOI: 10.1007/978-981-13-5934-7_30\nCITATIONS\n5READS\n321\n7 author s, including:\nLekshmi S Nair\nAmrit a Vishw a Vidyapee tham K ollam\n27 PUBLICA TIONS \xa0\xa0\xa0134 CITATIONS \xa0\xa0\xa0\nSEE PROFILE\nMay a Menon\nAmrit a Vishw a Vidyapee tham\n4 PUBLICA TIONS \xa0\xa0\xa028 CITATIONS \xa0\xa0\xa0\nSEE PROFILE\nAll c ontent f ollo wing this p age was uplo aded b y Lekshmi S Nair  on 21 A ugust 2020.\nThe user has r equest ed enhanc ement of the do wnlo aded file. Automated Review Analyzing SystemUsing Sentiment Analysis', 'T otalnumberof document(2)F−scoreneg=numberof negativedocument\nT otalnumberof document(3)F−scoreneu=numberof neutraldocument\nT otalnumberof document(4)The F-score and the accuracy of the system for all the three languages aregiven in the Table4. Table5shows accuracy obtained for the proposed systemby SAIL. The number of tweets that are classiﬁed into their respective classesin three languages are shown in the Fig.3.\nTable 4.Accuracy and F-score of the proposed system(Cross Validated)\nLanguage F-score Accuracy\nTamil 0.4832 0.5612\nHindi 0.5219 0.5322\nBengali 0.3942 0.4171 AMRITA-CEN@SAIL2015: Sentiment Analysis in Indian Languages 709Table 5.Testing result of the proposed system by SAIL\nLanguage Accuracy (in %) Positive (in %) Negative (in %) Neutral (in %)\nTamil 39.28 % 29.81 % 26.58 % 59.79 %\nHindi 55.67 % 45.79 % 57.37 % 80.0 %\nBengali 33.6 % 29.58 % 34.44 % 39.26 %', 'Amrita -CEN -Senti DB1:Improved Twitter  Dataset \nfor S entiment al Analysis and Application of Deep \nlearning  \n \nNaveenkumar K S   \nCenter for Computational Engineering \nand Networking (CEN)  \nAmrita School of Engineering , Amrita \nVishwa Vidyapeetham  \nCoimbatore, Tamil N adu, India.  \nnaveensivakumarr@gmail.com  Vinayakumar R  \nCenter for Computational Engineering \nand Networking (CEN)  \nAmrita School of Engineering , Amrita \nVishwa Vidyapeetham  \nCoimbatore, Tamil Nadu, India.  \nvinayakumarr77@gmail.com  \n Soman K P  \nCenter for Computat ional Engineering \nand Networking (CEN)  \nAmrita School of Engineering,  Amrita \nVishwa Vidyapeetham  \nCoimbatore, Tamil Nadu, India . \n \nAbstract — Powerful weapon in today’s world  is ones emotion \nis social media. They have the power to make an individual \ntrendin g overnight or even may pull down  anyone reputation.', 'number of negative words for the hotel than the positive words since the ARASreviews are completely based upon the sentiment analysis on this review set, it showedthe deviation.ARAS-generated sentiment values were empirically veriﬁed by comparing it withthe results of the star system for different hotels in TripAdvisor. The main disadvan-tage about the star system observed from this experiment was the lack of accuracy.Normally there are ﬁve-star ratings available for a product. Hence 1 star in the starratings can be equated with any value between 0 and 20%, mathematically. On theother hand, ARAS provides a precise absolute sentiment value to each product. Hencefor the comparison, we had to consider an upper limit, highest star value possible,and a lower limit, lowest star value possible, for each of the star rating.As Fig.3indicates, result generated by ARAS mostly stood in between the highestand lowest values of the star rating. This indicates the inefﬁciency of the star system indelivering a precise rating to the user. Also, at odd times, the ARAS ratings ﬂuctuatedmarginally from the star reviews. While going through the reviews it was found thatthis happened for those cases where the users had written more negative commentsagainst the hotels and had rated it between 1 and 3. For example, for a one-starrating, its', 'the star reviews. While going through the reviews it was found thatthis happened for those cases where the users had written more negative commentsagainst the hotels and had rated it between 1 and 3. For example, for a one-starrating, its highest possible value is 20%, while the users who gave such a rating werenormally those who completely disliked the hotel. Reviews from such users wouldcontain maximum number of negative words for the hotel than the positive wordssince the ARAS reviews are completely based upon the sentiment analysis on thisreview set, it showed the deviation.', 'words.  \n5) Expansion of the abbreviations : \nThis method is also one of the pre -processing techniques \nthat are followed means that the words such as CPU are \nexpanded into Central Processing Unit so as such  some of \nthe words are abbreviated to thei r fullest for m in the data. \nThe classification becomes easy when it comes to the \nexpansion of the abbreviated words.  \n6) Stop words Removal : \nThe stop words are  the unnecessary words that are found in \nthe data. Usually the stop words are “the”,”is” ,”they” etc.  \nFollowing , the steps the data is pre-processed followed by \nfeature extraction process. In the feature extraction task , the \ndesired features are extracted for the s entiment  \nclassification task.  Of the other met hods , the pre -processing \nstep is the first method in the pre -processing of the data \nwhen it comes to text.  \nIV. DATASET DESCRIPTION  \nIn this paper , the data is collected from the various online \ntweets. The tweets are categorized as the positive and the \nnegative t weets based on the subject matter to which they \nbelong to, they are labelled as 0, stands for the negative', '4 LI http:// If link is present in the tweet then 1, else 0\n5 QU ? If ? is present in the tweet then 1, else 0\n6 EX ! If ! is present in the tweet then 1, else 0\n7 SEN PO Positive If the word is from Sentiwordnet Positive ﬁle then 1, else 0\n8 SEN NE Negative If the word is from Sentiwordnet negative ﬁle then 1, else 0\n9 SEN NU Neutral If the word is from Sentiwordnet neutral ﬁle then 1, else 0', 'which if a symbol is present in the tweet, it is marked 1. These features areextracted from the twitter dataset as it contains various special characters suchas @, RT, # and few more which are enlisted in the Table 2. The stop words are removed from the tweets. All special symbols are removed except for thequestion mark and the exclamation mark as these punctuations has the abilityto change the meaning of a particular tweet.2.2 Naive Bayes AlgorithmNaive Bayes has been used in information retrieval for many years and recentlyit has been used for many machine learning researches [13]. Multinomial Naive Bayes has been carried out for this work [14]. In recent years, the work hasbeen focused on two basic instantiations of the classiﬁer Bernoulli model andmultinomial model [15]. Bernoulli model represents the document as a vector ofbinary features whereas the multinomial model uses vector of integer feature torepresent documents [16]. The multinomial model works on the assumption thatthe probability of each word event in a document is independent of the wordscontext and position in the document [17]. To normalize the error in the NaiveBayes, a small correction known as Laplacian Smoothing is included [ 18,19]. Generally the Naive Bayes is mathematically represented as,P(c|d)=p(c)/productdisplay', '3.1 W eb Scraping\nWeb scraping, also known as screen scraping, web data extraction, web harvesting,etc., is a technique used to extract large chunks of data from online websites. Theretrieved data is then stored in a ﬁle in the local computer network, usually in the CSVformat. Web scrapers perform the retrival of data from websites. Web scraping (akaweb crawling) can be divided into two steps, fetching the web pages, and extractingthe web contents from the page. The contents of the web page may be searched,parsed, copied or reformatted into a spreadsheet. Our method would scrap reviewsfrom a given Uniform Resource Locator (URL) and perform sentiment analysis onthe retrieved data. The user needs to provides the URL of the website of interest.Web scraping is performed on the web pages directed by this URL and the retrieveddata is stored in a local directory as a comma separated variable (csv) ﬁle.\n3.2 Sentiment Analysis', 'The experiment is conducted on Windows 64-bit machine with i7 core processorand 8 GB RAM. The tweets from the dataset are taken. The initial step ispreprocessing in which steps such as normalization and tokenization are doneand the output of this step is raw tokens. These tokens are then given as aninput for feature extractor. The feature extractor will take the tokens as inputand extract the features from these tokens. The words, Sentiwordnet are takenas features and binary features are also included so as to improve the featureextractor. Sentiwordnet, hashtags, retweet, links, question marks, exclamatorymarks are taken as binary features which means if any of these features arepresent then the output will be 1 else 0. The description of the binary featureis well illustrated in the given Table2In this paper, engrossment is given forfeature extraction. The features are extracted from the training dataset andstored in a text ﬁle. Using the features that are extracted, the classiﬁcation stepis proceeded to. There are diﬀerent algorithms that are used for the classiﬁcationin Machine learning. The algorithm which is used in this paper is Naive Bayesclassiﬁcation algorithm. This Naive Bayes algorithm works on the principle ofBayes theorem. The training dataset and testing dataset is given as input for theclassiﬁer,', 'Fig. 1.Flow diagram of the proposed systemTable 1.Normalized symbol\nSl.No Symbols Features\n1 @ User\n2 # Hash\n3 1,2 Numbers\n4 :-) Emoticons\n5 !,? Punct\n6 https:// URL\nthe classiﬁed outputs are taken into consideration. Naive Bayes classiﬁer is chosenfor the classiﬁcation purpose as the size of the dataset is very small. In machinelearning hunk SciPy library is used for classiﬁcation.2.1 Feature ExtractionThe words of the sentiwordnet are taken as features because it contains theclassiﬁed words of respective languages. The binary features are the features in 706 S. Se et al.Table 2.Binary feature description\nSl.No Symbol Binary Features Description\n1 HA # If # is present in the tweet then 1, else 0\n2 RT RT If RT is present in the tweet then 1, else 0\n3 AR @ If @ is present in the tweet then 1, else 0\n4 LI http:// If link is present in the tweet then 1, else 0\n5 QU ? If ? is present in the tweet then 1, else 0\n6 EX ! If ! is present in the tweet then 1, else 0', 'Pang and Lee [15] showed that SVM performed the best when classifying moviereviews as positive or negative. An important next step would be to further exploreSVM parameters for classifying reviews.\n5.4 Dealing with Contrapositive W ord\nThe model suggested in this paper does not support contrapositive words.\n5.5 Machine Learning\nUse of machine learning instead of lexicon method can considerably improve theaccuracy of the system. Though it also adds on the complexity of the system. How-ever, machine learning will increase the execution times as the machine has to learnon its own rather than comparing lexicon sets.\nAcknowledgementsWe are extremely thankful to Computer Science Engineering Department,at Amrita Vishwa Vidyapeetham, for providing all the resources and facilities for conducting theexperimentation.\nReferences', 'In the proposed system, feature extraction is the most crucial process as theaccuracy of the classiﬁer is based on the extracted feature. The ﬂow of the pro-posed system is depicted in the Fig.1. Generally for the text classiﬁcation prob-lem, preprocessing is to be done and is mandatory especially for twitter dataset.The preprocessing steps include normalization and tokenization. In tokenization,the tweets are further chunked into small instances called tokens. These tokensare normalized using normalization process in which superﬁcial variations areremoved from the words and are thus converted to the similar form. The commontype of normalization includes case folding and stemming [ 11]. Predominantly, stemming is avoided for Indian languages in case of text classiﬁcation as this leadsto stem the useful information into its root form. Case folding is used mainly forEnglish language as it has upper case and lower case letters [ 12]. This is not needed in case of Indian languages as no such case diﬀerences exist. The terms which arenormalized using the system are listed in Table1. Along with the features, themachine also learns from the training dataset which is already labelled. A smallpart of the data from the training dataset say about 10 % is taken and given forthe validation process. This is given as an input for the Naive Bayes classiﬁer', '2 Methodology', 'in this paper is Naive Bayesclassiﬁcation algorithm. This Naive Bayes algorithm works on the principle ofBayes theorem. The training dataset and testing dataset is given as input for theclassiﬁer, in which 10 % of the training data is taken as a validation data. Thedata are classiﬁed using Naive Bayes and the output of the classiﬁer will be thelabelled tweets with positive, negative and neutral. The accuracy of the classiﬁeris veriﬁed using F-score. The F-score is calculated for all the three classes. It isgiven belowF−scorepos=numberof positivedocument', 'It acts as a ﬁnal answer to the questionof how good the hotel is?This indicates the inefﬁciency of the star system in delivering a precise rating tothe user. Also, at odd times, the ARAS ratings ﬂuctuated marginally from the starreviews. While going through the reviews, it was found that this happened for thosecases where the users had written more negative comments against the hotels andhad rated it between 1 and 3. For example, for a one-star rating, its highest possiblevalue is 20%, while the users who gave such a rating were normally those whocompletely disliked the hotel. Reviews from such users would contain maximum', 'text data pre -processing comes here is that many languages \nare spoken world -wide so the pronunciation of the word \ndiffers in each place  so in order to spell the word correctly \nthe a ccent marks are being used.  Nowa days emoji are \nbecoming famous in such a way that words are being used \nless when compared to that of the emoji, so they are an \nirrelevant part when they come into the text classification so \nthey must be removed.   \n4) Removal of the white spaces : \n The text data comes with the lots of the complications such \nas the words are repeated in the random manner in ord er to \nexpress the emotion of a person in that particular context. \nFor example: “you are sooooooooo cuteeeeee” here the \nword “you are so cute” means  the same meaning but in \norder to stress the word that is to find the intensity of the \nword they are used so these type are replaced with the \nnormal type as stated above. Then coming to the removal of \nthe white spaces it is just removing the space in betwe en the \nwords.  \n5) Expansion of the abbreviations : \nThis method is also one of the pre -processing techniques \nthat are followed means that the words such as CPU are', 'word mapping that are conv erted into the meaningful space  \nby the semantic similarity. The training takes place by the \nnon-zero matrix method  which are smaller when compared \nto the total number of the words that present in the dataset.  \nC. Word Embedding  \nEmbedding layer has the learned weights  in them that is \nthey are a pre -trained model. They are used in the word  or \nfor each character  by character level  of extraction of \nfeatures which are a col lection of the information [19] [ 21] \nfrom the particular  content. The embedding layer works by \nmeans of providing a dense representation of the words in \nthe relative meaning that improves the model over the \nsparse representations , even though they are used in the  \nrepresentations like the bag o f words . Keras embedding \ntakes the input in such a way that the integer encoded in \nthem for each word are shown with the integer which are \nunique. The Embedding layer is a set  with random weights \nwhich learns the words in the training phase of the data  [20]. \nD. Text Pre -Processing  \nThe pre -processing is one of the main method in the text \nprocessing. The data comes with too many information', 'D. Text Pre -Processing  \nThe pre -processing is one of the main method in the text \nprocessing. The data comes with too many information \nwhich are very difficult to process, that is a tedious process \nfor the machine to understand the content. The pre -\nprocessin g steps are as follows they are:  \n1) Conversion to one case : \nWhen it comes to the pre -processing stage , the text contains \na lot of various style of the alphabets present in them, so in \norder to make the text in the uniform manner all the text are \nconverted i nto one case in common either in the upper case \nor in the lower case as a part of the pre -processing \ntechnique. Here in this paper the data is converted into the \nlower case.  \n2) Conversion of the numbers : \nAnother major challenge in the text data is that , the text data \ncontains a lot of numbers in them which must be removed, if \nnot removed or converted into the wo rds the vectorization \nwould be a challenging task, the desired feature extraction would be a problem in such cases. So the numbers found in \nthe data  are converted into the words as the part of the pre -\nprocessing technique. For example , the “23” will be', 'the features are extracted from them. The vectorising is done \nby the means of the assigning the weight to the extracted \nfeature for the process of extraction of the information. The \nterm document  matrix ( tdm) method is updated with the \ntfidf. The tfidf has the two parts ; term frequency (tf ) and  \ninverse document frequency (idf ). The term frequency  (tf) \nfunctions in such a way that it determines the total number \nof the word occurrence in the particu lar draft but when it \ncomes to the Inverse Document Frequency  (IDF)  it has two \ndifferent functions that are mindf and the maxdf , which are \nthe minimum occurrence and the maximum occurrence of \nthe words in the particular context. The formula is give n \nbelow b ased on which the tfidf calculates the word \noccurrence.  \n \nIEEE - 45670\n10th ICCCNT 2019 \nJuly 6-8, 2019, IIT - Kanpur, \nKanpur, India \nAuthorized licensed use limited to: Amrita School Of Engineering - Kollam. Downloaded on August 27,2024 at 04:42:00 UTC from IEEE Xplore.  Restrictions apply.', 'Rennie, J.D., et al.: Tackling the poor assumptions of naive bayes text classiﬁers.In: ICML, vol. 3 (2003)14. Jordan, A.: On discriminative vs. generative classiﬁers: a comparison of logisticregression and naive bayes. Adv. Neural Inf. Process. Syst. 14, 841 (2002) 15. Panda, M., Abraham, A., Patra, M.R.: Discriminative multinomial naive bayes fornetwork intrusion detection, pp. 5–10 (2010)16. Juan, A., Ney, H.: Reversing and smoothing the multinomial naive bayes textclassiﬁer. In: PRIS (2002)17. McCallum, A., Nigam, K.A.: Comparison of Event Models for Naive Bayes TextClassiﬁcation. In: AAAI/ICML-98 Workshop on Learning for Text Categorization,pp. 41–48 (1998)18. Lewis, D.D.: Naive bayes at forty: the independence assumption in informationretrieval. In: N´edellec, C., Rouveirol, C. (eds.) ECML 1998. LNCS, vol. 1398.Springer, Heidelberg (1998)19. Amor,', 'symb olic representation as that of the true positive, true \nnegative, false positive, false negative. Now the terms are \nshown in the Table II below:  \nTABLE II.  EXPLANATION OF CONFUS ION MATRIX  \nTerms  Definition  \nPositive (P)  The result is positive.  \nNegative (N)  The result is negative.  \nTrue Positive (TP)  Actual label is positive \nand the predicted is also \npositive.  \nTrue Negative (NP)  Actual label is negative \nand the predicted is also \nnegative.  \nFalse Positive (FP)  Actual is negative but the \npredicted is positive.  \nFalse Neg ative (FN)  Actual is positive but the \npredicted is negative.  \n \nSo, by this methods the data can be decided to which they \nbelong to. Even the terms like th e Accuracy, Precision, \nRecall, f 1-score are derived from the confusion matrix. The \naccuracy is calcula ted by TP and TN and dividing them by \nthe sum of TP, TN, FP, FN multiplied by 100. The model is \njudged based on the accuracy. Now the Precision is \ncalculated by TP divided by the sum of the TP and the FP', 'Positive Negative Neutral Total\nTamil 387 316 400 1103 560\nHindi 168 545 493 1222 467\nBengali 277 354 368 999500 708 S. Se et al.\n4 Experiments and Results', 'Majumder, Amir Zadeh, and Louis -Philippe Morency. "Context -\ndependent s entiment analysis in user -generated videos." \nIn Proceedings of the 55th Annual Meeting of the Association for \nComputational Linguistics (Volume 1: Long Papers) , pp. 873 -883. \n2017.  \n[21] Vinayakumar, R., K. P. So man, and Prabaharan Poornachandran. \n"Detecting malicious domain names using deep learning approaches \nat scale."  Journal of Intelligent & Fuzzy Systems  34, no. 3 (2018): \n1355 -1367.  \n[22] Vinayakumar, R., Prabaharan Poornachandran, and K. P. Soman. \n"Scalable frame work for cyber threat situational awareness based on \ndomain name systems data analysis." In  Big Data in Engineering \nApplications , pp. 113 -142. Springer, Singapore, 2018.  \n[23] Vinayakumar, R., K. P. Soman, and Prabaharan Poornachandran. \n"Evaluating deep learning  approaches to characterize and classify \nmalicious URL’s."  Journal of Intelligent & Fuzzy Systems  34, no. 3', 'Authorized licensed use limited to: Amrita School Of Engineering - Kollam. Downloaded on August 27,2024 at 04:42:00 UTC from IEEE Xplore.  Restrictions apply.   \nFor Term Frequency , the formula is  given in Equation 1 : \n \n\uf020\n\uf028 \uf029WTF WT\uf03d \uf020 \uf028\uf031\uf029\uf020\nFor Inverse Document Frequency , the formula is  given in \nEquation 2 : \n\uf020\n\uf028 \uf029 log\ntNidf wdf\uf0e6\uf0f6\uf03d\uf0e7\uf0f7\n\uf0e8\uf0f8 \uf020 \uf028\uf032\uf029\uf020\nB. Global Ve ctors ( Glovec ) \nThe Global Vectors ( Glovec ) is a model for the method of \ndistributed word representation. It i s a learning algorithm \nwhich is  very well suited for the unsupervised algorithm that \nconverts the words to the vectors. They are achieved by the \nword mapping that are conv erted into the meaningful space  \nby the semantic similarity. The training takes place by the \nnon-zero matrix method  which are smaller when compared', 'that is given to the deep learning algorithms, the results th at \nare obtained is tabulated below. Then the data is passed on \nto the various trial s run experimentation with the various \nspilts as mentioned in the dataset description of which the \nsplit 70:30 has outperformed well whose results are bein g \ntabulated below in Table III.  \nTABLE III.  RESULTS FOR DEEP  LEARNING APPROA CH USING TFIDF   \nFeatures  \nTFIDF  Classifiers  Accuracy  Precision  Recall  F-\nScore  \n10,000  LSTM  \n 49.2 53.2 42.6 44.9 \n20,000  50.3 42.6 44.5 43.8 \n30,000  49.1 33.9 32.5 33.2 \n40,000  50.8 50.1 50.3 50.3 \n10,000  GRU  53.5 51.2 51.6 50.7 \n20,000  49.2 48.6 48.7 47.4 \n30,000  55.3 52.5 53.8 48.6 \n40,000  51.2 50.5 50.1 50.2 \n10,000  Simple', 'Fig. 1Review system atAmazon\n Automated Review Analyzing System … 331', 'the sum of TP, TN, FP, FN multiplied by 100. The model is \njudged based on the accuracy. Now the Precision is \ncalculated by TP divided by the sum of the TP and the FP \nmultiplied by 100. The Recall is calculated by the T P \ndivided by the sum of the TP and the FN multi plied by 100. \nThen finally the f 1-score is calculated by double the times of \nthe precision multiplied by the recall divided by the sum of \nthe precision and recall multiplied by 100. So the statistical \nmeasures  decides the model performance by confusion \nmatrix.  \nVII. EXPERIMENTAL ANALYSIS AND RESULTS  \nWe used the train data to train the model with the feature \nextraction with the tfidf and Glovec. The feature extraction \nprocess is carr ied on by the method of vectoriz ing the data, \nsince the data used here is a text data , the data has to be pre -\nprocessed before that feature extraction task. The tfidf is \nused here by considering the features from 10,000 to 40,000 \nthat is given to the deep learning algorithms, the results th at \nare obtained is tabulated below. Then the data is passed on \nto the various trial s run experimentation with the various', '·Review system ·Lexicon method ·Web crawling\nA. C. Jishag ( B)·V . Rakhesh·S. Mohan·N. Vinayak V arma·V. S h a b u·L. S. Nair·M. Menon Department of Computer Science, Amrita School of Engineering, AmritapuriAmrita Vishwa Vidyapeetham, Bengaluru, Indiae-mail:jishagac@gmail.comV . Rakheshe-mail:vishnurakhesh7@gmail.comS. Mohane-mail:surajmohan44@gmail.comN. Vinayak V armae-mail:vinayakvarma007@gmail.comV. S h a b ue-mail:vaisakhshabu@gmail.comL. S. Naire-mail:lekshmisn@am.amrita.eduM. Menone-mail:mayamenon@am.amrita.edu© Springer Nature Singapore Pte Ltd. 2019Y .-C. Hu et al. (eds.),Ambient Communications and Computer Systems , Advances in Intelligent Systems and Computing 904,https://doi.org/10.1007/978-981-13-5934-7_30329 330 A. C. Jishag et al.\n1 Introduction', '30,000  55.3 52.5 53.8 48.6 \n40,000  51.2 50.5 50.1 50.2 \n10,000  Simple \nRNN  51.1 52.3 52.9 52.9 \n20,000  50.5 50.6 49.6 41.1 \n30,000  50.6 49.8 41.8 50.2 \n40,000  53.9 50.5 49.2 52.3 \n \nIEEE - 45670\n10th ICCCNT 2019 \nJuly 6-8, 2019, IIT - Kanpur, \nKanpur, India \nAuthorized licensed use limited to: Amrita School Of Engineering - Kollam. Downloaded on August 27,2024 at 04:42:00 UTC from IEEE Xplore.  Restrictions apply.  Then the Glovec is used for the distributed word \nrepresentation are taken for this approach. The Glovec that \nhas been used here is a pre -trained network that is allowed \nto be passed through the deep learning algorithms and the \nresults that are obtained a re tabulated be low in the Table IV . \nThe deep learning algorithms that are used here are the Long \nShort -Term Memory (LSTM) which has the ability to retain', '4 Experimentation Result', '2 Related Works', 'View publication stats', '"Evaluating deep learning  approaches to characterize and classify \nmalicious URL’s."  Journal of Intelligent & Fuzzy Systems  34, no. 3 \n(2018): 1333 -1343.  \n[24] Vinayakumar, R., Alazab, M., Soman, K.P., Poornachandran, P. and \nVenkatraman, S., 2019. Robust I ntelligent Malware Detection Using \nDeep Learning.  IEEE Access , 7, pp.46717 -46738.  \n[25] Vinayakumar, R., Alazab, M., Soman, K.P., Poornachandran, P., Al -\nNemrat, A. and Venkatraman, S., 2019. Deep Learning Approach for \nIntelligent Intrusion Detection System.  IEEE Access , 7, pp.41525 -\n41550.  \n \nIEEE - 45670\n10th ICCCNT 2019 \nJuly 6-8, 2019, IIT - Kanpur, \nKanpur, India \nAuthorized licensed use limited to: Amrita School Of Engineering - Kollam. Downloaded on August 27,2024 at 04:42:00 UTC from IEEE Xplore.  Restrictions apply.', '67 704 S. Se et al.', 'results that are obtained a re tabulated be low in the Table IV . \nThe deep learning algorithms that are used here are the Long \nShort -Term Memory (LSTM) which has the ability to retain \nthe long -term dependencies by having the ability of adding \nor removing the information in the cell state, binary class is \nbeing considered here by allowing the usage of the sigmoid \nfunction, they allow the flow of the numbers from 0 to 1. \nGated Recurrent Unit (GRU) works by correcting the \nvanishing gradient problem by the gates that are present in \nthem such as the update gate a nd the reset gate, those are the \ndecision making vectors on which the output is depended \non. The reset gate works in forgetting the past information \nfor which the model has been trained for.  Here a study has \nbeen done by comparing  three algori thms  along  with the \nglobal vectors (Gl ovec) of which Long Short -Term Memor y \n(LSTM) outperforms well gaining an accuracy of about \n75.3% which is the benchmark accuracy for this dataset as \nshown in the Table IV.  \nTABLE IV.  RESULTS FOR DEEP LEA RNING APPROACH  USING GLOVEC  \nMethod  Classifie rs Accuracy', 'In: N´edellec, C., Rouveirol, C. (eds.) ECML 1998. LNCS, vol. 1398.Springer, Heidelberg (1998)19. Amor, N.B., et al.: Naive bayes vs decision trees in intrusion detection systems.In: 2004 ACM Symposium on Applied Computing (2004)']
# Get optimal number of clusters using BIC
def get_optimal_clusters(embeddings, reduced_dim, max_clusters=10):
    bic_scores = []
    for n_clusters in range(1, max_clusters+1):
        _, log_likelihood, _, _, _ = gmm(embeddings, n_clusters)
        mean_params = n_clusters * reduced_dim
        cov_params = n_clusters * (reduced_dim * (reduced_dim + 1) // 2)
        pi_params = n_clusters - 1
        k = mean_params + cov_params + pi_params # Total number of params
        bic = -2 * log_likelihood + k * np.log(len(embeddings))
        bic_scores.append(bic)
    print(bic_scores)
    return np.argmin(bic_scores) + 1

a = umap(x, GPT4AllEmbeddings(), 7, 10)
optimal_clusters = get_optimal_clusters(a, 10)
responsibilities, _, _, _, _ = gmm(a, optimal_clusters)
clusters = np.argmax(responsibilities, axis=0)
print(optimal_clusters, clusters)
import matplotlib.pyplot as plt
from langchain_community.embeddings import GPT4AllEmbeddings
from sklearn.metrics import silhouette_score
import umap

embedder = GPT4AllEmbeddings()
vectorized_splits = np.array(embedder.embed_documents(x))
# Step 2: Apply UMAP for dimensionality reduction
reducer = umap.UMAP(n_neighbors=7, n_components=10, random_state=42)
a = reducer.fit_transform(vectorized_splits)
# Step 3: Determine optimal number of clusters
optimal_clusters = get_optimal_clusters(a, reduced_dim=10)
from sklearn.mixture import GaussianMixture
def get_optimal_clusters_with_gmm(embeddings, max_clusters=10):
    bic_scores = []
    print("Computing BIC scores for different numbers of clusters:")
    for n_clusters in range(2, max_clusters + 1):  # Include max_clusters in the loop
        # Initialize the GaussianMixture model
        gmm = GaussianMixture(n_components=n_clusters, covariance_type='full', random_state=42)
        # Fit the model to the embeddings
        gmm.fit(embeddings)
        # Compute the BIC score
        bic = gmm.bic(embeddings)
        bic_scores.append(bic)
        # Print the BIC score for the current number of clusters
        print(f"Clusters: {n_clusters}, BIC Score: {bic}")
    # Find the optimal number of clusters (lowest BIC score)
    optimal_clusters = np.argmin(bic_scores) + 1
    print("\nOptimal number of clusters:", optimal_clusters)

    return optimal_clusters, bic_scores
# Step 1: Embed your documents
embedder = GPT4AllEmbeddings()
vectorized_splits = np.array(embedder.embed_documents(x))

# Step 2: Apply UMAP for dimensionality reduction
reducer = umap.UMAP(n_neighbors=7, n_components=10, random_state=42)
a = reducer.fit_transform(vectorized_splits)
optimal_clusters, bic_scores = get_optimal_clusters_with_gmm(a, max_clusters=10)

print("\nBIC Scores:", bic_scores)
print("Optimal Clusters:", optimal_clusters)